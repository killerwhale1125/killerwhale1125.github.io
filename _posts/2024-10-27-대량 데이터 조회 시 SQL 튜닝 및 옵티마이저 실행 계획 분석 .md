---
title: 대량 데이터 MySQL 튜닝(Indexing) 및 옵티마이저 실행 계획 분석
description: 
author: killer whale
date: 2024-10-27 14:10:00 +0800
categories: [Blogging]
tags: [writing]
pin: true
render_with_liquid: false
---

SQL SELECT 시 데이터 수가 적다면 Query를 어떻게 작성하여도 대부분 큰 문제가 되지 않습니다. 하지만 **`한 테이블에 대략 100만개의 데이터가 저장되어있다면?`** 어떤 데이터를 조회할지에 대한 상태에 따라 다르겠지만 소요되는 시간이 급격히 증가 될 것이라는 것은 직감적으로 느낄 수 있습니다.<br/> 

이번 포스팅에서는 SQL 튜닝이 왜 중요하며 성능을 테스트하기 전 **`왜 디스크에서 가져오는 것이 속도가 느리며 MySQL의 옵티마이저가 어떠한 실행계획을 작성하는지`**에 대해 살펴보고 튜닝을 진행해보고자 합니다.

## 디스크의 읽기 방식

디스크 I/O 작업은 알다시피 비용이 많이 발생하는 작업입니다. 디스크에 있는 데이터를 조회할 때 원판을 생각하면 이해하기 쉬운데 **`디스크 헤더를 특정 데이터가 있는 원판의 위치로 이동`**시켜야만 해당 데이터를 읽는다고 간단히 표현하겠습니다. 이러한 디스크 작업에도 두가지의 종류가 있습니다.

**랜덤 I/O & 순차 I/O**

![Untitled](https://killerwhale1125.github.io/assets/img/post/io_image.png){: width="300" height="300" .normal}

**순차 I/O(왼쪽)와 랜덤 I/O(오른쪽)** **`이미지 출처 - RealMySQL 8.0 1권`**

그림처럼 가장 위쪽 MySQL 서버에 세개의 데이터가 있으며 톱니바퀴를 MySQL의 옵티마이저라 가정합시다. 


| 조회 방식  | 디스크 접근 횟수 |
|:-------|:----------|
| 순차 I/O | 1번        |
| 랜덤 I/O | 3번        |

순차 I/O 방식은 찾아야 할 **`세개의 데이터가 디스크에 정렬되어있다고`** 가정할 경우 MySQL 서버의 세개 데이터를 주머니에 넣어 옵티마이저에게 부탁하는 것을 예로 들 수 있습니다.
<br/>
반면 랜덤 I/O 방식은 디스크에 찾아야 할 **`데이터가 정렬되어있지 않고 중구난방으로 떨어져있기 때문에`** 디스크에 있는 데이터를 하나하나 찾아가며 조회를 해야합니다.

**`즉 순차 I/O는 디스크 헤더를 1번 움직인 반면, 랜덤 I/O는 디스크 헤더를 여러번 움직여 찾아야 하기 때문에 3번의 접근이 발생합니다.`**

> 해당 내용은 HDD를 기준을 설명하였지만 HDD보다 더욱 빠른 SSD도 마찬가지로 순차 I/O보다 랜덤 I/O가 Throughput(처리량)이 떨어집니다.
{: .prompt-tip }

위 내용을 한마디로 표현해보자면 '디스크에 데이터가 정렬되어있기 때문에 데이터를 빠르게 가져오도록 계획할 수 있다' 라고 표현할 수 있습니다.

## MySQL 옵티마이저

디스크의 조회 방식을 간단히 살펴보았으니 MySQL 엔진의 가장 중요한 옵티마이저에 대해서 간단히 설명하겠습니다.

![Untitled](https://killerwhale1125.github.io/assets/img/post/mysql_structure.png){: width="500" height="500" .normal}

**MySQL 전체 구조** **`이미지 출처 - RealMySQL 8.0 1권`**

원하는 데이터를 조회하기 위해 MySQL Client가 MySQL 서버에 요청하게 되면 첫번째로 MySQL 엔진을 거치게 됩니다. 이때 엔진에서는 Client가 보낸 SQL Query가 올바른지 검사 후 옵티마이저는 해당 Query를 분석하고 최적화하여 실행계획을 세웁니다.
그 후 핸들러 API를 통하여 MySQL 스토리지엔진 (InnoDB) 로 해당 쿼리를 디스크에 가져오도록 명령합니다.<br/>

결국 MySQL **`옵티마이저가 세운 계획에 따라 얼마나 효율적으로 데이터를 조회할 지 판단`**이 되며 SQL Query를 작성하는 개발자는 **`어떤 순서로 테이블에 접근할지 인덱스를 사용할지 어떤 인덱스를 사용할지를 설정하여 옵티마이저가 설정한대로 계획을 세우도록 유도하는 것이 핵심`**입니다.

그럼 어떻게 효율적으로 데이터를 조회하도록 유도할 수 있을까요?


## Index

**인덱스(Index)란?**
> 데이터를 빨리 찾기 위해 특정 컬럼을 기준으로 미리 정렬해놓은 표

위 순차 I/O 에서 정렬되어 있었기 때문에 접근 횟수를 줄일 수 있었습니다. 인덱스(Index) 정의 또한 미리 표를 정렬해 놓는다고 하였는데 **`결국 위 내용들은 모두 인덱싱을 위한 빌드업이였으며 튜닝의 가장 핵심적인 요소`**라고 생각합니다. 

우선 간단한 예시로 설명하겠습니다.

![Untitled](https://killerwhale1125.github.io/assets/img/post/index_sample.png){: width="800" height="500" .normal}

인덱스를 직접 생성하게 되면 우리 눈에는 안 보이지만 위와 같은 표가 시스템 내부적으로 생성됩니다. 나이를 기준으로 정렬해놓은 표를 가지고 있기 때문에, 나이를 기준으로 데이터를 조회할 때 접근 횟수도 줄이며 훨씬 빠르게 찾을 수 있습니다.

> 인덱스 종류가 다양하지만 자세한 인덱스에 대한 정리는 다른 포스팅으로 작성 계획입니다.
{: .prompt-tip }


## Index를 적용하여 성능 측정 및 실행 계획 분석

> 아래 설명할 내용은 개인 프로젝트로 개발하며 기록한 내용입니다.

테스트를 실행할 테이블의 정보는 아래와 같습니다.
![Untitled](https://killerwhale1125.github.io/assets/img/post/index_test.png){: width="800" height="500" .normal}

favorite 테이블은 제외하고 Member와 Post 테이블에 50만, 100만개의 데이터를 각각 삽입하였습니다. 또한 카테고리 테이블은 사진에는 없지만 10개의 카테고리가 저장되어 있습니다. 

![Untitled](https://killerwhale1125.github.io/assets/img/post/member_count.png){: width="350" height="50" .normal}
![Untitled](https://killerwhale1125.github.io/assets/img/post/post_count.png){: width="350" height="50" .normal}

<br/>
첫번째 테스트는 간단히 주소로 게시물을 조회하는 예제입니다.
```text
EXPLAIN ANALYZE SELECT * FROM post p 
WHERE
    p.state='Incheon'
    and p.city='mapo'
    and p.town='sinsa';
```
<br/>
**실행 결과**

```text
-> Filter: ((p.town = 'sinsa') and (p.city = 'mapo') and (p.state = 'Incheon'))  (cost=100954 rows=994) (actual time=0.0547..1016 rows=2 loops=1)
    -> Table scan on p  (cost=100954 rows=993592) (actual time=0.0424..968 rows=1e+6 loops=1)
```

![Untitled](https://killerwhale1125.github.io/assets/img/post/query_excute1.png){: width="800" height="200" .normal}
![Untitled](https://killerwhale1125.github.io/assets/img/post/query_execute1_ms.png){: width="800" height="200" .normal}

위 실행결과는 옵티마이저가 스스로 판단하여 실행 순서를 정의한 것입니다. rows를 보면 1e+6이라고 적혀있는데 이는 게시물 데이터 100만개로서 풀테이블 스캔을 의미합니다. 또한 실행 결과를 보면 1000ms가 소요된 것을 확인할 수 있습니다. 예제에서는 만약 100만개지만 데이터가 1000만개 아니 1억개라면 어떨까요? 
이와 같이 데이터 Size가 늘어날 수록 조회 비용이 더욱 커져 성능이 감소할 것 입니다. <br/><br/>

**어떠한 부분을 Index하는 것이 현명할까?**

상황 마다 다르겠지만 위와 같은 상황에선 조건이 간단하기에 WHERE 조건인 state와 city, town에 멀티 컬럼 인덱스를 구성하는 것이 효율적이라고 생각합니다.
<br/><br/>

**주소에 Index 적용**

```text
CREATE INDEX idx_state_city_town on post(state, city, town);
```

**실행 결과**

```text
-> Index lookup on p using idx_state_city_town (state='Incheon', city='mapo', town='sinsa')  (cost=0.7 rows=2) (actual time=0.0442..0.0556 rows=2 loops=1)
```

![Untitled](https://killerwhale1125.github.io/assets/img/post/query_execute2.png){: width="800" height="200" .normal}
![Untitled](https://killerwhale1125.github.io/assets/img/post/query_execute2_ms.png){: width="800" height="200" .normal}



인덱스를 적용하였기 때문에 아예 **`디스크로 접근하지도 않고 바로 인덱스 테이블에서만 가져오는 것을 확인`**할 수 있습니다. 또한 **`1000ms 에서 0.091ms로 성능이 약 11배 정도 개선되었습니다.`** 
이는 간단한 예제이기 때문에 문제를 해결하기 수월했지만, 좀더 복잡한 JOIN, GROUP BY 예제를 통하여 조금 더 테스트해보겠습니다.
